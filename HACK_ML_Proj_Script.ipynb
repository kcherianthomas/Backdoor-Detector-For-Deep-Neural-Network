{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HACK_ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwoI-Wjr1CC0"
      },
      "source": [
        "## Backdoor Detection in DNN using STRIP Technique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6kKixQn0gef"
      },
      "source": [
        "Group Members:\r\n",
        "*Rahul Petkar* : **rsp431**\r\n",
        "*Shubham Ingale* : **ski227**\r\n",
        "*Cherian Thomas* : **kct298**\r\n",
        "*Akhand Singh* : **aps646**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGOj8SZq_uhr"
      },
      "source": [
        "Note: Follow the same process for all badnets from B1, B2....Bn as defined in the Readme File (i.e; Substituting Required Paths before running the Script)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6v-SB_oTIpp"
      },
      "source": [
        "import keras\r\n",
        "import sys\r\n",
        "import h5py\r\n",
        "import numpy as np\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "import random\r\n",
        "import statistics\r\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-A-rbwz6q5p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d075fdc-52a5-4cc9-a9a6-def2842158b6"
      },
      "source": [
        "# mount required drive for testing\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZh8HyRBUyxM"
      },
      "source": [
        "def data_loader(filepath):\r\n",
        "    data = h5py.File(filepath, 'r')\r\n",
        "    x_data = np.array(data['data'])\r\n",
        "    y_data = np.array(data['label'])\r\n",
        "    x_data = x_data.transpose((0,2,3,1))\r\n",
        "\r\n",
        "    return x_data, y_data\r\n",
        "\r\n",
        "def data_preprocess(x_data):\r\n",
        "    return x_data/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgcuEEIfXGQU"
      },
      "source": [
        "def PrintAccOnGivenModelAndData(model_filename, x_test, y_test):\r\n",
        "  bd_model = keras.models.load_model(model_filename)\r\n",
        "  clean_label_p = np.argmax(bd_model.predict(x_test), axis=1)\r\n",
        "  class_accu = np.mean(np.equal(clean_label_p, y_test))*100\r\n",
        "  print('Classification accuracy:', class_accu)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igO01Bhl__gn"
      },
      "source": [
        "Path Substitution can be done in the below Code for Specific Badnets B1, B2....Bn\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO2zm1bMVDp6"
      },
      "source": [
        "# This is where you paste to dataset link to generate the filename\r\n",
        "ValidationData_filename = str(\"/content/drive/MyDrive/Colab Notebooks/clean_validation_data.h5\")\r\n",
        "model_filename = str(\"/content/drive/MyDrive/Colab Notebooks/sunglasses_bd_net.h5\")\r\n",
        "# These are given test datasets \r\n",
        "Poisoned_data_filename = str(\"/content/drive/MyDrive/Colab Notebooks/sunglasses_poisoned_data.h5\")\r\n",
        "clean_test_filename=str(\"/content/drive/MyDrive/Colab Notebooks/clean_test_data.h5\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crIQM_ueZkc4"
      },
      "source": [
        "# This function is used to calculate the detection boundary based on the Validation data\r\n",
        "# The validation data is used to calculate Detection boundary\r\n",
        "# It is achieved by superimposition of random validation images\r\n",
        "\r\n",
        "def FindDetectionBoundary(model_filename, ValidationData_filename):\r\n",
        "  x_validation, y_validation = data_loader(ValidationData_filename)\r\n",
        "  x_validation = data_preprocess(x_validation)\r\n",
        "  bd_model = keras.models.load_model(model_filename)\r\n",
        "  N = 10\r\n",
        "  lengthValidData = len(x_validation)  \r\n",
        "  SuperImposeImg_Pred = np.zeros((lengthValidData, N))\r\n",
        "  SuperImposeImg = []\r\n",
        "  #SuperImposeImg = np.zeros(N)\r\n",
        "  for idx,i in enumerate(x_validation):\r\n",
        "    for _ in range(N):\r\n",
        "      SuperImposeImg.append(cv2.addWeighted(i, 1, random.choice(x_validation), 1, 0,dtype = cv2.CV_32F))\r\n",
        "    arr = np.array(SuperImposeImg)\r\n",
        "    #print(SuperImposeImg)\r\n",
        "    clean_label_p = np.argmax(bd_model.predict(arr), axis=1)\r\n",
        "    SuperImposeImg.clear()\r\n",
        "    #print(clean_label_p)\r\n",
        "    newarr = list(clean_label_p)\r\n",
        "    #for j in range(N):\r\n",
        "    SuperImposeImg_Pred[idx] = clean_label_p\r\n",
        "\r\n",
        "  Yi_Denom = y_validation.max() \r\n",
        "  Label_Map = {}\r\n",
        "  Total_validation_Images = len(SuperImposeImg_Pred)\r\n",
        "  Hsum = [] * Total_validation_Images\r\n",
        "  Normal_H = [] * Total_validation_Images\r\n",
        "  for i in range(Total_validation_Images):\r\n",
        "    yi = []*N\r\n",
        "    for j in SuperImposeImg_Pred[i]:\r\n",
        "      if j not in Label_Map:\r\n",
        "        Label_Map[j] = 0\r\n",
        "      Label_Map[j] += 1\r\n",
        "    idx = 0\r\n",
        "    Hn = 0.0\r\n",
        "    for Key,Val in Label_Map.items():\r\n",
        "      yi_temp = float(Val/Yi_Denom) \r\n",
        "      yi.append(-1 * yi_temp * math.log2(yi_temp))\r\n",
        "      Hn += yi[idx]\r\n",
        "      idx+=1\r\n",
        "    Label_Map.clear()\r\n",
        "    Hsum.append(float(Hn))\r\n",
        "    Normal_H.append(float(Hsum[i]/N))\r\n",
        "\r\n",
        "  # Mean and Standard Deviation are calculated\r\n",
        "  Mean_H = statistics.mean(Normal_H) \r\n",
        "  StdD_H = statistics.stdev(Normal_H)\r\n",
        "\r\n",
        "  # The Z_score value for One percentile is considered to get Detection Boundary\r\n",
        "  Z_score = -2.326\r\n",
        "  DetectionBoundary = float(Mean_H + Z_score* StdD_H)\r\n",
        "  return DetectionBoundary\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlsfdxt9BRwb"
      },
      "source": [
        "# This the Predict class function\r\n",
        "# It takes in input image and processes it\r\n",
        "# The function then makes prediction on 10 images created by superimposing randomly selected 10 images from the Validation Data (Which is pre_processed i.e; divided by 255)\r\n",
        "# The prediction entrophy is calculated and compared to Detection Boundary to generate Ouput Labels\r\n",
        "def PredictClass(Test_Image):\r\n",
        "  Test_Image = data_preprocess(Test_Image)\r\n",
        "  N = 10\r\n",
        "  SuperImposeImg = []  \r\n",
        "  for j in range(N):\r\n",
        "    SuperImposeImg.append(cv2.addWeighted(Test_Image, 1, random.choice(x_validation), 1, 0,dtype = cv2.CV_32F))\r\n",
        "  arr = np.array(SuperImposeImg)\r\n",
        "  TestDataPred = np.argmax(bd_model.predict(arr), axis=1)\r\n",
        "  \r\n",
        "  Yi_Denom = y_validation.max() \r\n",
        "  Label_Map = {}\r\n",
        "  Total_Poison_Images = len(TestDataPred)\r\n",
        "  yi = []*N\r\n",
        "\r\n",
        "  # Backdoored Class N + 1 is calculated as below\r\n",
        "  Backdoor = y_validation.max() + 1\r\n",
        "  Output_Labels = 0\r\n",
        "  Output_Labels = np.zeros(1)\r\n",
        "  Hsum = 0.0\r\n",
        "  for j in TestDataPred:\r\n",
        "    if j not in Label_Map:\r\n",
        "      Label_Map[j] = 0\r\n",
        "    Label_Map[j] += 1\r\n",
        "  idx = 0\r\n",
        "  Hn = 0.0\r\n",
        "  for Key,Val in Label_Map.items():\r\n",
        "    yi_temp = float(Val/Yi_Denom) \r\n",
        "    yi.append(-1 * yi_temp * math.log2(yi_temp))\r\n",
        "    Hn += yi[idx]\r\n",
        "    idx+=1\r\n",
        "  Hsum = float(Hn)\r\n",
        "  CurrentEntrophy = float(Hsum/N)\r\n",
        "  if CurrentEntrophy<=DetectionBoundary:\r\n",
        "    Output_Labels[0] = Backdoor\r\n",
        "  else:\r\n",
        "    Output_Labels = np.argmax(bd_model.predict(np.array([Test_Image,] )), axis=1)\r\n",
        "  return Output_Labels[0]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ffyqdNTKUtN"
      },
      "source": [
        "Run Below Scipt Once (Detection Boundary is calculated below)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOc3NzqaDs2Q"
      },
      "source": [
        "# Calculate Detection Boundary\r\n",
        "# This below code Should be run before using the PredictClass Function\r\n",
        "# The Below code calculated Detection Boundary which is referenced by the PredictClass function\r\n",
        "DetectionBoundary = FindDetectionBoundary(model_filename, ValidationData_filename)\r\n",
        "x_validation, y_validation = data_loader(ValidationData_filename)\r\n",
        "x_validation = data_preprocess(x_validation)\r\n",
        "bd_model = keras.models.load_model(model_filename)\r\n",
        "X_test, Y_test = data_loader(Poisoned_data_filename)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7erPWLR1RIG"
      },
      "source": [
        "Class prediction of a Single Vanilla test Image from Poisoned Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUwCQ6tW1Ml6",
        "outputId": "1063cbb6-e1c2-43b5-c62d-bf6bbcf55f7b"
      },
      "source": [
        "# Single Test Image \r\n",
        "X_test, Y_test = data_loader(Poisoned_data_filename)\r\n",
        "Single_Test_Image = X_test[0,:,:,:]\r\n",
        "print(\"Predicted Class: \", PredictClass(Single_Test_Image))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:  1283.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsaRmyoqYHtH"
      },
      "source": [
        "The PredictClass function used below is to find out from the given **Poisoned Test Data Set**, as to how many images are categorised as backdoored."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh_U2U0nDgkN",
        "outputId": "6ad8405e-3fac-4a98-ddb5-b5bd0219e85c"
      },
      "source": [
        "Total_Backdoored_Images = 0\r\n",
        "# The Backdoored class representation according to project definition\r\n",
        "Backdoored_Class = y_validation.max() + 1\r\n",
        "for i in X_test:\r\n",
        "  # PredictClass function takes one image as input and the return the output label on that image\r\n",
        "  # PredictClass can be used independently to find out the Label on an individual input\r\n",
        "  # PredictClass internally processes image by dividing it by 255, so make sure that a vanilla image is passed to it\r\n",
        "  out = PredictClass(i)\r\n",
        "  if out == Backdoored_Class:\r\n",
        "    Total_Backdoored_Images+=1\r\n",
        "\r\n",
        "print(\"Total Backdoored Images Found: \", Total_Backdoored_Images)\r\n",
        "print(\"Total Images In the Test Set: \", len(X_test))\r\n",
        "print(\"Accuracy on Poisoned DataSet: \", float(Total_Backdoored_Images/len(X_test)) * 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Backdoored Images Found:  12231\n",
            "Total Images In the Test Set:  12830\n",
            "Accuracy on Poisoned DataSet:  95.33125487139516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAyUCiJGvyGs"
      },
      "source": [
        "The PredictClass function used below to check the performance on **Clean Test Data** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYyhFVlzm9su",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fd664f7-3bda-494c-fe1a-8677f53c90f4"
      },
      "source": [
        "X_test, Y_test = data_loader(clean_test_filename)\r\n",
        "Total_Clean_Images = 0\r\n",
        "# The Backdoored class representation according to project definition\r\n",
        "Backdoored_Class = y_validation.max() + 1\r\n",
        "for i in X_test:\r\n",
        "  # PredictClass function takes one image as input and the return the output label on that image\r\n",
        "  # PredictClass can be used independently to find out the Label on an individual input\r\n",
        "  # PredictClass internally processes image by dividing it by 255, so make sure that a vanilla image is passed to it\r\n",
        "  out = PredictClass(i)\r\n",
        "  if out != Backdoored_Class:\r\n",
        "    Total_Clean_Images+=1\r\n",
        "\r\n",
        "print(\"Total Clean Images Found: \", Total_Clean_Images)\r\n",
        "print(\"Total Images In the Clean Test Set: \", len(X_test))\r\n",
        "print(\"Accuracy on Clean DataSet: \", float(Total_Clean_Images/len(X_test)) * 100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Clean Images Found:  12303\n",
            "Total Images In the Clean Test Set:  12830\n",
            "Accuracy on Clean DataSet:  95.89243959469992\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}